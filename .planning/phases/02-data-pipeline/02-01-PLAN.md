---
phase: 02-data-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/requirements.txt
  - backend/pipeline/__init__.py
  - backend/pipeline/clients/__init__.py
  - backend/pipeline/clients/asknews_client.py
  - backend/pipeline/services/__init__.py
  - backend/pipeline/services/entity_service.py
  - backend/utils/constants.py
autonomous: true
user_setup:
  - service: asknews
    why: "AskNews API authentication for news/stories endpoints"
    env_vars:
      - name: ASKNEWS_API_KEY
        source: "AskNews Dashboard -> API Keys (after creating account)"
    dashboard_config:
      - task: "Create AskNews account at asknews.app"
        location: "Sign up with Spelunker tier ($250/mo, 1,500 base requests)"

must_haves:
  truths:
    - "Backend can authenticate with AskNews API using OAuth2 credentials"
    - "Entity name variations normalize to canonical names before storage"
    - "Entity variations dict covers all 10 curated entities with common name variations"
  artifacts:
    - path: "backend/pipeline/clients/asknews_client.py"
      provides: "AskNews SDK wrapper with async methods"
      min_lines: 80
      contains: "AskNewsSDK.*fetch_news.*fetch_stories"
    - path: "backend/pipeline/services/entity_service.py"
      provides: "Entity normalization with variation mapping"
      min_lines: 50
      contains: "ENTITY_VARIATIONS.*normalize_entity_name"
    - path: "backend/utils/constants.py"
      provides: "Extended entity variations dict"
      contains: "gpt_4o.*claude.*gemini.*cursor.*lovable"
  key_links:
    - from: "backend/pipeline/clients/asknews_client.py"
      to: "asknews SDK"
      via: "import AskNewsSDK"
      pattern: "from asknews_sdk import AskNewsSDK"
    - from: "backend/pipeline/services/entity_service.py"
      to: "backend/utils/constants.py"
      via: "import ENTITY_VARIATIONS"
      pattern: "from backend\\.utils\\.constants import ENTITY_VARIATIONS"
---

<objective>
Set up AskNews SDK integration and entity normalization service.

Purpose: Establish the foundation for data ingestion by configuring authenticated AskNews API access and ensuring entity name variations map correctly to canonical names from day 1.
Output: Working AskNews client with OAuth2 auth and validated entity normalization logic.
</objective>

<execution_context>
@/Users/daniswhoiam/.claude/get-shit-done/workflows/execute-plan.md
@/Users/daniswhoiam/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-data-pipeline/02-RESEARCH.md

# Phase 1 outputs (assumed complete)
Entity, Article, SentimentTimeseries models exist in backend/db/models.py
AsyncSession with expire_on_commit=False in backend/db/session.py
FastAPI with lifespan in backend/main.py
Curated entity list (10 entities) in backend/utils/constants.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install AskNews SDK and retry dependencies</name>
  <files>backend/requirements.txt</files>
  <action>
Add AskNews Python SDK and tenacity library to backend/requirements.txt:

```
asknews>=0.4.0
tenacity>=8.2.0
structlog>=24.1.0
```

Version constraints:
- asknews 0.4.0+ for OAuth2 client credentials and async support
- tenacity 8.2+ for async exponential backoff retry decorators
- structlog 24.1+ for JSON structured logging

DO NOT pin to exact versions - use >= to allow patch updates.
  </action>
  <verify>
Run `docker-compose exec backend pip list | grep -E 'asknews|tenacity|structlog'` to confirm installation.
  </verify>
  <done>
requirements.txt contains asknews, tenacity, and structlog with correct version constraints.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create AskNews SDK client wrapper</name>
  <files>backend/pipeline/clients/asknews_client.py, backend/pipeline/clients/__init__.py, backend/pipeline/__init__.py</files>
  <action>
Create async AskNews client wrapper at backend/pipeline/clients/asknews_client.py:

**Directory structure:**
- backend/pipeline/__init__.py (empty, package marker)
- backend/pipeline/clients/__init__.py (empty, package marker)
- backend/pipeline/clients/asknews_client.py (implementation)

**Implementation requirements:**

1. **AskNewsClient class** with OAuth2 authentication:
   - Initialize AskNewsSDK with api_key from environment (ASKNEWS_API_KEY)
   - Set scopes=["news", "stories"] to request only needed permissions
   - Store client as instance variable

2. **fetch_news(entity_name: str, limit: int = 10) -> list[dict]** method:
   - Call client.news.search_news() with query=entity_name
   - Use string_guarantee=[entity_name] to enforce entity appears in results
   - Transform response to standard dict format with keys: external_id, title, entity_name, sentiment, url, source_url, published_at
   - Log using structlog: "asknews_news_fetched" with entity name and article count
   - Raise exceptions on API errors (do NOT swallow errors)

3. **fetch_stories(entity_name: str, limit: int = 10) -> list[dict]** method:
   - Call client.stories.search_stories() with query=entity_name
   - Extract story clusters with sentiment time-series data
   - Return list of dicts with keys: story_id, entity_name, headline, sentiment_timeseries (list), reddit_threads (list)
   - Log using structlog: "asknews_stories_fetched" with entity and story count
   - NOTE: Exact /stories response structure needs validation - log full response for first call

4. **Error handling:**
   - Let exceptions propagate (don't catch and return empty lists)
   - Log errors with structlog.error() including entity name and error details
   - Use exc_info=True for full tracebacks

**Structlog configuration:**
Import structlog, call structlog.get_logger() at module level.

**Why async:** AskNews SDK supports async operations - use async def for all methods.

**DO NOT implement retry logic here** - retry will be handled by tenacity decorator in jobs (Plan 02/03).
  </action>
  <verify>
1. Check file exists: `ls backend/pipeline/clients/asknews_client.py`
2. Verify imports: `grep -E 'from asknews_sdk import|structlog' backend/pipeline/clients/asknews_client.py`
3. Verify methods exist: `grep -E 'async def fetch_news|async def fetch_stories' backend/pipeline/clients/asknews_client.py`
  </verify>
  <done>
AskNewsClient class exists with OAuth2 auth, fetch_news() and fetch_stories() async methods, structured logging, and standard dict response format.
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement entity normalization service</name>
  <files>backend/pipeline/services/entity_service.py, backend/pipeline/services/__init__.py, backend/utils/constants.py</files>
  <action>
**Step 1: Extend backend/utils/constants.py with ENTITY_VARIATIONS dict**

Add ENTITY_VARIATIONS dict covering all 10 curated entities (from PROJECT.md):

```python
ENTITY_VARIATIONS = {
    'gpt_4o': {
        'canonical': 'GPT-4o',
        'variations': [
            'GPT-4o', 'GPT 4o', 'gpt-4o', 'GPT4o', 'GPT-4-O',
            "OpenAI's GPT-4o", 'GPT-4o mini', 'GPT 4o mini',
            'openai gpt-4o', 'gpt 4 o'
        ]
    },
    'claude': {
        'canonical': 'Claude',
        'variations': [
            'Claude', 'claude', 'Anthropic Claude', 'Claude 3',
            'Claude Opus', 'Claude Sonnet', 'Claude Haiku',
            'claude-opus', 'claude-sonnet', 'claude 3.5'
        ]
    },
    'gemini': {
        'canonical': 'Gemini',
        'variations': [
            'Gemini', 'Google Gemini', 'Gemini 1.5', 'gemini-pro',
            'gemini pro', 'gemini flash', 'Gemini AI'
        ]
    },
    'llama': {
        'canonical': 'Llama',
        'variations': [
            'Llama', 'LLaMA', 'Llama 3', 'Meta Llama',
            'llama-2', 'llama-3', 'Llama2', 'Llama3'
        ]
    },
    'mistral': {
        'canonical': 'Mistral',
        'variations': [
            'Mistral', 'Mistral AI', 'Mistral 7B', 'Mixtral',
            'mistral-7b', 'mixtral-8x7b'
        ]
    },
    'cursor': {
        'canonical': 'Cursor',
        'variations': [
            'Cursor', 'cursor', 'Cursor IDE', 'Anysphere Cursor',
            'cursor-ai', 'cursor.sh', 'Cursor editor'
        ]
    },
    'lovable': {
        'canonical': 'Lovable',
        'variations': [
            'Lovable', 'lovable', 'Lovable.dev', 'lovable.dev'
        ]
    },
    'v0': {
        'canonical': 'v0',
        'variations': [
            'v0', 'Vercel v0', 'v0.dev', 'v0 by Vercel'
        ]
    },
    'github_copilot': {
        'canonical': 'GitHub Copilot',
        'variations': [
            'GitHub Copilot', 'Github Copilot', 'Copilot',
            'github-copilot', 'GH Copilot', 'Copilot AI'
        ]
    },
    'replit': {
        'canonical': 'Replit',
        'variations': [
            'Replit', 'replit', 'Repl.it', 'repl.it', 'Replit AI'
        ]
    }
}
```

**Step 2: Create backend/pipeline/services/entity_service.py**

Implement two functions:

1. **normalize_entity_name(extracted_name: str) -> str | None:**
   - Strip whitespace, convert to lowercase for matching
   - Iterate ENTITY_VARIATIONS, check if extracted_name matches any variation
   - Use bidirectional substring matching: `variation.lower() in normalized OR normalized in variation.lower()`
   - Return canonical name if match found, else None
   - DO NOT raise exceptions - return None for non-curated entities

2. **get_entity_id_by_name(canonical_name: str, db_session) -> int | None:**
   - Query Entity table for entity with matching canonical name
   - Return entity.id if found, else None
   - Use async session from backend/db/session.py

**Logging:**
- Log entity normalization hits/misses at DEBUG level
- Log unknown entities at INFO level for future audit

**DO NOT:**
- Use regex (substring matching is sufficient)
- Create new Entity records (assume Phase 1 seeded entities)
- Cache results in memory (premature optimization)

**Step 3: Create backend/pipeline/services/__init__.py**

Empty file (package marker).
  </action>
  <verify>
1. Check ENTITY_VARIATIONS exists: `grep -A 5 'ENTITY_VARIATIONS = {' backend/utils/constants.py`
2. Check normalize function: `grep 'def normalize_entity_name' backend/pipeline/services/entity_service.py`
3. Test normalization manually:
   ```python
   from backend.pipeline.services.entity_service import normalize_entity_name
   assert normalize_entity_name("GPT 4o") == "GPT-4o"
   assert normalize_entity_name("claude-opus") == "Claude"
   assert normalize_entity_name("unknown") is None
   ```
  </verify>
  <done>
ENTITY_VARIATIONS dict covers all 10 entities with common variations. normalize_entity_name() returns canonical names for known variations and None for unknown entities.
  </done>
</task>

</tasks>

<verification>
Run these checks after task completion:

1. **Dependencies installed:**
   ```bash
   docker-compose exec backend pip list | grep -E 'asknews|tenacity|structlog'
   ```

2. **AskNews client exists:**
   ```bash
   python -c "from backend.pipeline.clients.asknews_client import AskNewsClient; print('OK')"
   ```

3. **Entity normalization works:**
   ```python
   from backend.pipeline.services.entity_service import normalize_entity_name
   assert normalize_entity_name("GPT-4o mini") == "GPT-4o"
   assert normalize_entity_name("Anthropic Claude") == "Claude"
   assert normalize_entity_name("random entity") is None
   ```

4. **File structure correct:**
   ```bash
   ls backend/pipeline/clients/asknews_client.py
   ls backend/pipeline/services/entity_service.py
   ```
</verification>

<success_criteria>
- AskNews SDK (asknews>=0.4.0) installed in backend container
- AskNewsClient class implements fetch_news() and fetch_stories() with OAuth2 auth
- ENTITY_VARIATIONS dict covers all 10 curated entities with 5+ variations each
- normalize_entity_name() correctly maps variations to canonical names
- All imports resolve without errors
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-pipeline/02-01-SUMMARY.md`
</output>
