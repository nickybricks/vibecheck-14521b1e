---
phase: 01-foundation-storage
plan: 02
type: execute
wave: 2
depends_on: ["01"]
files_modified:
  - backend/db/__init__.py
  - backend/db/base.py
  - backend/db/models.py
  - backend/db/session.py
  - backend/alembic.ini
  - backend/alembic/env.py
  - backend/alembic/script.py.mako
  - backend/alembic/versions/001_create_schema.py
autonomous: true

must_haves:
  truths:
    - "SQLAlchemy models exist for entities, articles, and sentiment_timeseries tables"
    - "Database session factory supports async operations with proper connection pooling"
    - "Alembic can generate and apply migrations for schema changes"
    - "Schema supports TimescaleDB-compatible time-series patterns"
  artifacts:
    - path: "backend/db/models.py"
      provides: "ORM models for Entity, Article, SentimentTimeseries"
      min_lines: 60
      contains: "class Entity.*class Article.*class SentimentTimeseries"
    - path: "backend/db/session.py"
      provides: "Async engine and session factory"
      contains: "create_async_engine.*async_sessionmaker"
    - path: "backend/db/base.py"
      provides: "DeclarativeBase with AsyncAttrs"
      contains: "class Base.*AsyncAttrs.*DeclarativeBase"
    - path: "backend/alembic/versions/001_create_schema.py"
      provides: "Initial schema migration"
      min_lines: 40
  key_links:
    - from: "backend/db/models.py"
      to: "backend/db/base.py"
      via: "import Base"
      pattern: "from backend\\.db\\.base import Base"
    - from: "backend/db/session.py"
      to: "environment variables"
      via: "DATABASE_URL from config"
      pattern: "DATABASE_URL.*getenv|from.*config import"
    - from: "backend/alembic/env.py"
      to: "backend/db/base.py"
      via: "import Base.metadata"
      pattern: "from backend\\.db\\.base import Base"
---

<objective>
Create SQLAlchemy async ORM models and Alembic migrations for core database schema.

Purpose: Establish the data layer with entities, articles, and sentiment time-series tables, enabling storage of article metadata and pre-computed sentiment aggregates (STOR-01, STOR-02).
Output: Working async database models with initial migration, ready for CRUD operations in Phase 2.
</objective>

<execution_context>
@/Users/daniswhoiam/.claude/get-shit-done/workflows/execute-plan.md
@/Users/daniswhoiam/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@/Users/daniswhoiam/Projects/vibecheck/.planning/PROJECT.md
@/Users/daniswhoiam/Projects/vibecheck/.planning/ROADMAP.md
@/Users/daniswhoiam/Projects/vibecheck/.planning/STATE.md
@/Users/daniswhoiam/Projects/vibecheck/.planning/phases/01-foundation-storage/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Create SQLAlchemy 2.0 async base and session management</name>
  <files>
    backend/db/__init__.py
    backend/db/base.py
    backend/db/session.py
  </files>
  <action>
Create database foundation modules following research patterns:

1. Create backend/db/__init__.py:
   - Import and export Base, engine, AsyncSessionLocal, get_session
   - Import models (will be created next)

2. Create backend/db/base.py:
   - Import DeclarativeBase and AsyncAttrs from sqlalchemy.orm
   - Define Base class inheriting from AsyncAttrs and DeclarativeBase
   - Add docstring explaining AsyncAttrs enables lazy-loaded relationships with async

3. Create backend/db/session.py:
   - Import create_async_engine, async_sessionmaker, AsyncSession from sqlalchemy.ext.asyncio
   - Get DATABASE_URL from os.getenv with default postgresql+asyncpg://vibecheck:password@localhost:5432/vibecheck
   - Create engine with create_async_engine:
     * echo=False (set via SQL_ECHO env var)
     * pool_size=10
     * max_overflow=20
     * pool_pre_ping=True (verify connections before use)
   - Create AsyncSessionLocal factory with async_sessionmaker:
     * engine=engine
     * class_=AsyncSession
     * expire_on_commit=False (CRITICAL: prevents implicit queries after commit)
   - Define async get_session() dependency for FastAPI:
     * async with AsyncSessionLocal() as session
     * yield session
     * Handle commit/rollback/close in try/except/finally

CRITICAL: expire_on_commit=False is required for async to prevent post-commit attribute access from triggering implicit database queries.
  </action>
  <verify>
Files exist and contain correct patterns:
- grep "AsyncAttrs" backend/db/base.py
- grep "expire_on_commit=False" backend/db/session.py
- grep "create_async_engine" backend/db/session.py
- grep "pool_pre_ping=True" backend/db/session.py
  </verify>
  <done>
Database session management configured with async engine, session factory, and FastAPI dependency injection
  </done>
</task>

<task type="auto">
  <name>Create ORM models for entities, articles, and sentiment time-series</name>
  <files>
    backend/db/models.py
  </files>
  <action>
Create SQLAlchemy models following schema from research (STOR-01, STOR-02):

1. Import required types:
   - from datetime import datetime
   - from sqlalchemy import String, Text, Integer, Float, TIMESTAMP, CheckConstraint, ForeignKey
   - from sqlalchemy.orm import Mapped, mapped_column, relationship
   - from backend.db.base import Base

2. Create Entity model:
   - __tablename__ = "entities"
   - id: Mapped[int] = mapped_column(primary_key=True)
   - name: Mapped[str] = mapped_column(String(255), unique=True, nullable=False)
   - category: Mapped[str] = mapped_column(String(50), nullable=False) # "model" or "tool"
   - created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), default=datetime.utcnow)

3. Create Article model:
   - __tablename__ = "articles"
   - id: Mapped[int] = mapped_column(primary_key=True)
   - external_id: Mapped[str] = mapped_column(String(255), unique=True, index=True, nullable=False)
   - title: Mapped[str] = mapped_column(String(500), nullable=False)
   - url: Mapped[str] = mapped_column(Text, unique=True, nullable=False)
   - source_name: Mapped[str | None] = mapped_column(String(255), nullable=True)
   - published_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, index=True)
   - sentiment_score: Mapped[float | None] = mapped_column(Float, nullable=True)
   - created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), default=datetime.utcnow)
   - Add __table_args__ with CheckConstraint for sentiment_score between -1 and 1

4. Create SentimentTimeseries model:
   - __tablename__ = "sentiment_timeseries"
   - id: Mapped[int] = mapped_column(primary_key=True)
   - entity_id: Mapped[int] = mapped_column(ForeignKey("entities.id"), nullable=False, index=True)
   - timestamp: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, index=True)
   - period: Mapped[str] = mapped_column(String(10), nullable=False) # "hourly" or "daily"
   - sentiment_mean: Mapped[float | None] = mapped_column(Float, nullable=True)
   - sentiment_min: Mapped[float | None] = mapped_column(Float, nullable=True)
   - sentiment_max: Mapped[float | None] = mapped_column(Float, nullable=True)
   - sentiment_std: Mapped[float | None] = mapped_column(Float, nullable=True)
   - article_count: Mapped[int | None] = mapped_column(Integer, nullable=True)
   - created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), default=datetime.utcnow)
   - Add __table_args__ with composite index on (entity_id, timestamp DESC)
   - Add __table_args__ with CheckConstraint for sentiment values between -1 and 1

Use Mapped type hints and mapped_column() (SQLAlchemy 2.0+ pattern). All timestamps TIMESTAMP WITH TIME ZONE (UTC).
  </action>
  <verify>
Validate models:
- grep "class Entity" backend/db/models.py
- grep "class Article" backend/db/models.py
- grep "class SentimentTimeseries" backend/db/models.py
- grep "Mapped\[int\]" backend/db/models.py
- grep "CheckConstraint" backend/db/models.py
- python -c "from backend.db.models import Entity, Article, SentimentTimeseries; print('Models import successfully')"
  </verify>
  <done>
Three ORM models created (Entity, Article, SentimentTimeseries) with proper type hints, indexes, and constraints for time-series sentiment storage
  </done>
</task>

<task type="auto">
  <name>Initialize Alembic and create initial migration</name>
  <files>
    backend/alembic.ini
    backend/alembic/env.py
    backend/alembic/script.py.mako
    backend/alembic/versions/001_create_schema.py
  </files>
  <action>
Set up Alembic for async migrations following research patterns:

1. Initialize Alembic:
   - cd backend && alembic init alembic
   - This creates alembic/ directory with env.py, script.py.mako

2. Modify backend/alembic.ini:
   - Set sqlalchemy.url = postgresql+asyncpg://vibecheck:password@postgres:5432/vibecheck
   - Update script_location to point to alembic/ directory

3. Modify backend/alembic/env.py for async support:
   - Import asyncio, create_async_engine, pool from sqlalchemy
   - Import Base from backend.db.base
   - Import all models: from backend.db.models import Entity, Article, SentimentTimeseries
   - Set target_metadata = Base.metadata
   - Keep run_migrations_offline() as-is
   - Modify run_migrations_online() to use async:
     * async def run_migrations_online()
     * connectable = create_async_engine(config.get_main_option("sqlalchemy.url"), poolclass=pool.NullPool)
     * async with connectable.begin() as connection: await connection.run_sync(do_run_migrations)
     * def do_run_migrations(connection): context.configure(...); with context.begin_transaction(): context.run_migrations()
   - Change main block to: if offline: run_migrations_offline() else: asyncio.run(run_migrations_online())

4. Generate initial migration:
   - cd backend && alembic revision --autogenerate -m "Create initial schema"
   - This creates migration file in alembic/versions/ detecting all three tables

5. Apply migration to verify it works:
   - Start postgres: docker-compose up -d postgres
   - Wait for healthy: sleep 5
   - Run migration: cd backend && alembic upgrade head
   - Verify tables created: docker-compose exec postgres psql -U vibecheck -d vibecheck -c "\dt"
   - Should show: entities, articles, sentiment_timeseries, alembic_version

CRITICAL: env.py must use create_async_engine and asyncio.run() for async compatibility.
  </action>
  <verify>
Validate Alembic setup:
- ls backend/alembic/env.py backend/alembic.ini backend/alembic/versions/*.py
- grep "asyncio.run" backend/alembic/env.py
- grep "create_async_engine" backend/alembic/env.py
- grep "target_metadata = Base.metadata" backend/alembic/env.py
- docker-compose up -d postgres && sleep 10 && cd backend && alembic upgrade head
- docker-compose exec postgres psql -U vibecheck -d vibecheck -c "\dt" | grep "entities\|articles\|sentiment_timeseries"
  </verify>
  <done>
Alembic configured for async migrations with initial schema migration applied, creating entities, articles, and sentiment_timeseries tables in PostgreSQL
  </done>
</task>

</tasks>

<verification>
After completion, verify:
1. All three ORM models (Entity, Article, SentimentTimeseries) exist in backend/db/models.py
2. AsyncSessionLocal factory configured with expire_on_commit=False
3. Alembic migrations run successfully: alembic upgrade head creates all tables
4. Database schema matches requirements: psql \d shows correct indexes and constraints
5. Schema is TimescaleDB-compatible (entity_id, timestamp indexes present)
</verification>

<success_criteria>
- SQLAlchemy 2.0 async models exist for all three tables
- Database session factory supports async with proper pooling
- Alembic migrations create schema with correct indexes and constraints
- Schema supports time-series queries (indexed by entity_id, timestamp)
- Models use Mapped type hints and CheckConstraints for data validation
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-storage/01-02-SUMMARY.md`
</output>
